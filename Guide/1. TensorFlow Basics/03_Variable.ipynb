{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8MvCcG0qI_G",
        "outputId": "77da523b-fa09-472c-e519-e137ce14d46c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 변수\n",
        "# TensorFlow 변수는 프로그램이 조작하는 공유 영구 상태를 나타내는 권장 방법\n",
        "# 변수는 tf.Variable 클래스를 통해 생성 및 추적\n",
        "# tf.Variable은 ops를 실행하여 값을 변경할 수 있는 텐서를 나타냄\n",
        "# 특정 ops를 사용하면 텐서의 값을 읽고 수정할 수 있음\n",
        "\n",
        "\n",
        "# 변수 만들기\n",
        "import tensorflow as tf\n",
        "\n",
        "# my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "# my_variable = tf.Variable(my_tensor)\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors\n",
        "# bool_variable = tf.Variable([False, False, False, True])\n",
        "# complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
        "\n",
        "# print(\"Shape:\", my_variable.shape)\n",
        "# print(\"DType:\", my_variable.dtype)\n",
        "# print(\"As NumPy:\", my_variable.numpy())\n",
        "\n",
        "# print(\"A variable:\", my_variable)\n",
        "# print(\"Viewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
        "# print(\"Index of highest value:\", tf.math.argmax(my_variable))\n",
        "\n",
        "# This creates a new tensor. it does not reshape the variable\n",
        "# print(\"Copying and reshaping:\", tf.reshape(my_variable, [1, 4]))\n",
        "\n",
        "# tf.Variable.assign을 사용해 텐서 재할당\n",
        "# assign을 호출해도 (일반적으로) 새로운 텐서를 할당하지 않고, 기존의 메모리가 재사용됨\n",
        "# a = tf.Variable([2.0, 3.0])\n",
        "# a.assign([1, 2])\n",
        "\n",
        "# try:\n",
        "#     a.assign([1.0, 2.0, 3.0])\n",
        "# except Exception as e:\n",
        "#     print(f\"{type(e).__name__}: {e}\")\n",
        "\n",
        "# a = tf.Variable([2.0, 3.0])\n",
        "# b = tf.Variable(a)\n",
        "# a.assign([5, 6])\n",
        "\n",
        "# a and b are different\n",
        "# print(a.numpy())\n",
        "# print(b.numpy())\n",
        "\n",
        "# There are other versions of assign\n",
        "# print(a.assign_add([2, 3]).numpy())\n",
        "# print(a.assign_sub([7, 9]).numpy())\n",
        "\n",
        "\n",
        "# 수명 주기. 이름 지정 및 감시\n",
        "# Python 기반 TensorFlow에서 tf.Variable 인스턴스는 다른 Python 객체와 같은 수명 주기를 가짐\n",
        "# 변수에 대한 참조가 없으면 자동으로 할당 해제\n",
        "# a = tf.Variable(my_tensor, name=\"Mark\")\n",
        "# b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
        "\n",
        "# These are elementwise-unequal, despite having the same name\n",
        "# print(a == b)\n",
        "\n",
        "# 변수 생성 시 trainable을 false로 설정하여 변수의 그래디언트를 끌 수 있음\n",
        "# 그래디언트가 필요하지 않은 변수의 예는 훈련 단계 카운터\n",
        "# step_counter = tf.Variable(1, trainable=False)\n",
        "\n",
        "\n",
        "# 변수 및 텐서 배치\n",
        "# 더 나은 성능을 위해 TensorFlow는 dtype과 호환되는 가장 빠른 기기에 텐서 및 변수를 배치하려고 시도함\n",
        "# 이는 대부분의 변수가 GPU(사용 가능한 경우)에 배치됨을 의미\n",
        "# GPU가 사용 가능하더라도 부동 텐서와변수를 CPU에 배치할 수 있음\n",
        "# with tf.device(\"CPU:0\"):\n",
        "#     # Create some tensors\n",
        "#     a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "#     b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "#     c = tf.matmul(a, b)\n",
        "\n",
        "# print(c)\n",
        "\n",
        "# 한 기기에서 변수 또는 텐서의 위치를 설정하고 다른 기기에서 계산 가능\n",
        "# 이 경우, 기기 간에 데이터를 복사해야 하므로 지연 발생\n",
        "# tf.config.set_soft_device_placement이 기본적으로 항상 켜져있어, GPU가 없는 기기에서도 실행됨 (곱셈은 CPU에서 실행됨)\n",
        "with tf.device(\"CPU:0\"):\n",
        "    a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "    b = tf.constant([[1.0, 2.0, 3.0]])\n",
        "\n",
        "with tf.device(\"GPU:0\"):\n",
        "    # Element-wise multiply\n",
        "    k = a * b\n",
        "\n",
        "print(k)"
      ]
    }
  ]
}