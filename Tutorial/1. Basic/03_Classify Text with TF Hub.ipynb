{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phbbIMvrZ8cr",
        "outputId": "002f934f-ac4a-42c9-9fb1-9b11beac4a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 49s 2s/step - loss: 0.6589 - accuracy: 0.5268 - val_loss: 0.6198 - val_accuracy: 0.5843\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.5614 - accuracy: 0.6974 - val_loss: 0.5150 - val_accuracy: 0.7371\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 48s 2s/step - loss: 0.4312 - accuracy: 0.8184 - val_loss: 0.4181 - val_accuracy: 0.8208\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 46s 2s/step - loss: 0.3190 - accuracy: 0.8785 - val_loss: 0.3558 - val_accuracy: 0.8494\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.2328 - accuracy: 0.9135 - val_loss: 0.3213 - val_accuracy: 0.8525\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.1706 - accuracy: 0.9441 - val_loss: 0.3072 - val_accuracy: 0.8665\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.1248 - accuracy: 0.9619 - val_loss: 0.3053 - val_accuracy: 0.8702\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.0895 - accuracy: 0.9766 - val_loss: 0.3104 - val_accuracy: 0.8738\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.0643 - accuracy: 0.9853 - val_loss: 0.3216 - val_accuracy: 0.8729\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 47s 2s/step - loss: 0.0468 - accuracy: 0.9920 - val_loss: 0.3367 - val_accuracy: 0.8729\n",
            "49/49 - 12s - loss: 0.3589 - accuracy: 0.8588 - 12s/epoch - 239ms/step\n",
            "loss: 0.359\n",
            "accuracy: 0.859\n"
          ]
        }
      ],
      "source": [
        "# Keras와 TensorFlow를 사용한 영화 리뷰 텍스트 분류\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "# 드라이브 마운트 및 패키지 경로 작업\n",
        "# drive.mount(\"/content/drive\", force_remount=True)\n",
        "# my_path = \"/content/package\"\n",
        "# save_path = \"/content/drive/MyDrive/Colab Notebooks/package\"        # 패키지가 저장될 경로\n",
        "\n",
        "# os.symlink(save_path, my_path)\n",
        "# sys.path.insert(0, my_path)\n",
        "\n",
        "# 패키지 설치\n",
        "# !pip install --target=$my_path tensorflow-hub\n",
        "# !pip install --target=$my_path tensorflow-datasets\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# print(\"Version: \", tf.__version__)\n",
        "# print(\"Eager mode: \", tf.executing_eagerly())\n",
        "# print(\"Hub version: \", hub.__version__)\n",
        "# print(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
        "\n",
        "# IMDB 데이터셋 다운로드\n",
        "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
        "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\",\n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)\n",
        "\n",
        "# 데이터 탐색\n",
        "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
        "# train_examples_batch\n",
        "# train_labels_batch\n",
        "\n",
        "# 모델 구성\n",
        "## 문장을 임베딩시키기 위해 tensorflow hub 모델을 사용하는 keras층 생성\n",
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"          # 사전 훈련된 텍스트 임베딩 모델\n",
        "hub_layer = hub.KerasLayer(embedding,\n",
        "                           input_shape=[],\n",
        "                           dtype=tf.string,\n",
        "                           trainable=True)\n",
        "# 입력 텍스트 길이에 상관없이 임베딩의 출력 크기는 (num_examples, embedding_dimension)\n",
        "# hub_layer(train_examples_batch[:3])\n",
        "\n",
        "## 모델 생성\n",
        "model = tf.keras.Sequential([\n",
        "    hub_layer,\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)])\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "## 손실 함수와 옵티마이저\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),    # 확률을 다루는데 적합\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)\n",
        "\n",
        "# 모델 평가\n",
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "    print(\"%s: %.3f\" % (name, value))"
      ]
    }
  ]
}
